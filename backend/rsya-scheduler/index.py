import json
import os
from typing import Dict, Any, List
from datetime import datetime, timedelta
import psycopg2
import psycopg2.extras
import boto3
import requests

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –±–∞—Ç—á–µ–π
AVG_TIME_PER_CAMPAIGN = 7  # —Å–µ–∫—É–Ω–¥ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É 1 –∫–∞–º–ø–∞–Ω–∏–∏ (–ø–æ —Ñ–∞–∫—Ç—É ~6-7 —Å–µ–∫)
SAFE_TIMEOUT = 25  # 25 —Å–µ–∫ (Cloud Function timeout 30 —Å–µ–∫ —Å –∑–∞–ø–∞—Å–æ–º)
BATCH_SIZE = 7  # 7 –∫–∞–º–ø–∞–Ω–∏–π √ó 7 —Å–µ–∫ = ~49 —Å–µ–∫, –Ω–æ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —É–∫–ª–∞–¥—ã–≤–∞–µ–º—Å—è –≤ 25 —Å–µ–∫

def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    '''
    Business: Scheduler –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —á–∏—Å—Ç–∫–∏ –ø–ª–æ—â–∞–¥–æ–∫ –†–°–Ø (3 —Ä–∞–∑–∞/–¥–µ–Ω—å)
    Args: event - dict —Å httpMethod (CRON —Ç—Ä–∏–≥–≥–µ—Ä –∏–ª–∏ —Ä—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫)
          context - –æ–±—ä–µ–∫—Ç —Å request_id
    Returns: HTTP response —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π
    '''
    method: str = event.get('httpMethod', 'GET')
    
    if method == 'OPTIONS':
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Max-Age': '86400'
            },
            'body': ''
        }
    
    dsn = os.environ.get('DATABASE_URL')
    if not dsn:
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({'error': 'DATABASE_URL not configured'})
        }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä force_all –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
    params = event.get('queryStringParameters') or {}
    force_all = params.get('force_all') == 'true'
    
    try:
        conn = psycopg2.connect(dsn)
        conn.autocommit = False
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å
        print(f"üîç Checking for projects to schedule at {datetime.now()} (force_all={force_all})")
        
        if force_all:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ ‚Äî –±–µ—Ä—ë–º –í–°–ï –∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
            cursor.execute("""
                SELECT 
                    s.id as schedule_id,
                    s.project_id,
                    s.interval_hours,
                    p.yandex_token,
                    p.campaign_ids
                FROM t_p97630513_yandex_cleaning_serv.rsya_project_schedule s
                JOIN t_p97630513_yandex_cleaning_serv.rsya_projects p ON p.id = s.project_id
                WHERE s.is_active = TRUE
                  AND p.yandex_token IS NOT NULL
                ORDER BY s.project_id
                LIMIT 10
            """)
        else:
            # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
            cursor.execute("""
                SELECT 
                    s.id as schedule_id,
                    s.project_id,
                    s.interval_hours,
                    p.yandex_token,
                    p.campaign_ids
                FROM t_p97630513_yandex_cleaning_serv.rsya_project_schedule s
                JOIN t_p97630513_yandex_cleaning_serv.rsya_projects p ON p.id = s.project_id
                WHERE s.is_active = TRUE
                  AND s.next_run_at <= CURRENT_TIMESTAMP
                  AND p.yandex_token IS NOT NULL
                ORDER BY s.next_run_at
                LIMIT 5
            """)
        
        projects = cursor.fetchall()
        print(f"üìä Found {len(projects)} projects to schedule")
        
        if not projects:
            conn.close()
            return {
                'statusCode': 200,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({
                    'success': True,
                    'message': 'No projects to schedule',
                    'scheduled': 0
                })
            }
        
        total_batches = 0
        results = []
        
        for project in projects:
            try:
                batches_created = schedule_project(project, cursor, conn, context)
                total_batches += batches_created
                
                # –û–±–Ω–æ–≤–ª—è–µ–º next_run_at
                cursor.execute("""
                    UPDATE t_p97630513_yandex_cleaning_serv.rsya_project_schedule
                    SET next_run_at = NOW() + make_interval(hours => %s),
                        last_run_at = NOW(),
                        updated_at = NOW()
                    WHERE id = %s
                """, (project['interval_hours'], project['schedule_id']))
                
                results.append({
                    'project_id': project['project_id'],
                    'batches_created': batches_created,
                    'status': 'success'
                })
                
            except Exception as e:
                print(f"‚ùå Error scheduling project {project['project_id']}: {str(e)}")
                results.append({
                    'project_id': project['project_id'],
                    'status': 'error',
                    'error': str(e)
                })
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print(f"‚úÖ Scheduled {len(projects)} projects, {total_batches} batches total")
        
        return {
            'statusCode': 200,
            'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({
                'success': True,
                'scheduled_projects': len(projects),
                'total_batches': total_batches,
                'results': results
            })
        }
        
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"‚ùå Scheduler error: {str(e)}")
        print(f"‚ùå Traceback: {error_trace}")
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({'error': str(e), 'traceback': error_trace})
        }


def schedule_project(project: Dict[str, Any], cursor, conn, context: Any) -> int:
    '''
    –°–æ–∑–¥–∞—ë—Ç –±–∞—Ç—á–∏ –∫–∞–º–ø–∞–Ω–∏–π –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Message Queue
    Returns: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π
    '''
    project_id = project['project_id']
    campaign_ids = project['campaign_ids']
    yandex_token = project['yandex_token']
    
    # –ü–∞—Ä—Å–∏–º campaign_ids –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
    if isinstance(campaign_ids, str):
        campaign_ids = json.loads(campaign_ids)
    
    if not campaign_ids:
        print(f"‚ö†Ô∏è Project {project_id} has no campaigns")
        return 0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –±–∞—Ç—á–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω—ã –Ω–µ–¥–∞–≤–Ω–æ (–∑–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–µ–π)
    cursor.execute("""
        SELECT COUNT(*) as count 
        FROM t_p97630513_yandex_cleaning_serv.rsya_campaign_batches 
        WHERE project_id = %s AND created_at > NOW() - INTERVAL '5 minutes'
    """, (project_id,))
    
    recent_batches = cursor.fetchone()['count']
    if recent_batches > 0:
        print(f"‚ö†Ô∏è Project {project_id} already has {recent_batches} batches created in last 5 minutes, skipping")
        return 0
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏
    batches = []
    for i in range(0, len(campaign_ids), BATCH_SIZE):
        batch = campaign_ids[i:i + BATCH_SIZE]
        batches.append(batch)
    
    total_batches = len(batches)
    print(f"üì¶ Project {project_id}: {len(campaign_ids)} campaigns ‚Üí {total_batches} batches")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞—Ç—á–∏ –≤ –ë–î
    for batch_number, batch_campaign_ids in enumerate(batches, start=1):
        cursor.execute("""
            INSERT INTO t_p97630513_yandex_cleaning_serv.rsya_campaign_batches 
            (project_id, campaign_ids, batch_number, total_batches, status)
            VALUES (%s, %s, %s, %s, 'pending')
            RETURNING id
        """, (
            project_id,
            json.dumps(batch_campaign_ids),
            batch_number,
            total_batches
        ))
        
        batch_id = cursor.fetchone()['id']
        
        batch_data = {
            'batch_id': batch_id,
            'project_id': project_id,
            'campaign_ids': batch_campaign_ids,
            'yandex_token': yandex_token,
            'batch_number': batch_number,
            'total_batches': total_batches
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Message Queue (–¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏)
        send_to_mq(batch_data)
        
        # –°–†–ê–ó–£ –≤—ã–∑—ã–≤–∞–µ–º Worker —á–µ—Ä–µ–∑ HTTP (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
        invoke_worker_sync(batch_data)
    
    return total_batches


def send_to_mq(message: Dict[str, Any]) -> None:
    '''–û—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ –≤ Message Queue'''
    from botocore.config import Config
    
    queue_url = 'https://message-queue.api.cloud.yandex.net/b1gga4kkbv0csaelq94p/dj60000000b1egur05em/rsyacleaner'
    access_key = os.environ.get('YANDEX_MQ_ACCESS_KEY_ID')
    secret_key = os.environ.get('YANDEX_MQ_SECRET_KEY')
    
    if not access_key or not secret_key:
        raise Exception('Message Queue credentials not configured')
    
    print(f"üîë Using access key: {access_key[:8]}... (masked)")
    
    sqs = boto3.client(
        'sqs',
        endpoint_url='https://message-queue.api.cloud.yandex.net',
        region_name='ru-central1',
        aws_access_key_id=access_key,
        aws_secret_access_key=secret_key,
        config=Config(signature_version='v4')
    )
    
    print(f"üì§ Sending batch {message['batch_number']}/{message['total_batches']} to queue...")
    
    response = sqs.send_message(
        QueueUrl=queue_url,
        MessageBody=json.dumps(message)
    )
    
    print(f"‚úÖ Sent batch {message['batch_number']}/{message['total_batches']} to MQ (MessageId: {response.get('MessageId', 'N/A')})")


def invoke_worker_sync(batch_data: Dict[str, Any]) -> None:
    '''–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ Worker —á–µ—Ä–µ–∑ HTTP (–¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)'''
    worker_url = 'https://functions.poehali.dev/2642bac6-6d47-4fda-86e9-a10c458a2d81'
    
    try:
        print(f"üöÄ Invoking Worker directly for batch {batch_data['batch_number']}/{batch_data['total_batches']}...")
        
        response = requests.post(
            worker_url,
            json=batch_data,
            headers={'Content-Type': 'application/json'},
            timeout=120  # 2 –º–∏–Ω—É—Ç—ã —Ç–∞–π–º–∞—É—Ç (Worker –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–æ 90 —Å–µ–∫)
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Worker processed batch {batch_data['batch_number']}: {result.get('successful', 0)} successful, {result.get('failed', 0)} failed")
        else:
            print(f"‚ö†Ô∏è Worker returned status {response.status_code}: {response.text[:200]}")
    
    except requests.exceptions.Timeout:
        print(f"‚è±Ô∏è Worker timeout for batch {batch_data['batch_number']} (still processing in background)")
    except Exception as e:
        print(f"‚ùå Failed to invoke Worker for batch {batch_data['batch_number']}: {str(e)}")